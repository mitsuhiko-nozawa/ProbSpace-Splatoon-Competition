{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from Functions import prepro\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "FEATURE_SELECTION = False\n",
    "tgt_encode = False\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66125, 304)\n",
      "(28340, 303)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../../data/Processed/train2.csv\")\n",
    "test_df = pd.read_csv(\"../../data/Processed/test2.csv\")\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[\"y\"].values\n",
    "train_df = train_df.drop(\"y\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add disconnection info\n",
    "\n",
    "train_df = prepro.add_disconnection(train_df)\n",
    "test_df = prepro.add_disconnection(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df[\"good-special-A1\"].corr(train_df[\"good-sub-A1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add info about numeric column\n",
    "# 武器データの中のnum_colsを持つ特徴について、チーム内の統計量を計算、levelは結構効いてる\n",
    "\n",
    "num_cols = [\n",
    "    \"level\", \"range-main\", \"range-bullet-main\", \"distant-range_sub\", \n",
    "    \"rapid\", \"atack\", \"ink-sub\", \"fav-main\", \"good-special\", \"DPS\", \"kill_time_ika-main\",\n",
    "    \"front_gap_human-main\", \"front_gap_ika-main\", \"rensya_frame-main\", \"saidai_damege-main\", \"damage_min-sub\", \n",
    "    \"damage_max-sub\", \"install_num-sub\", \"good-sub\", \"damage_max-special\", \n",
    "    \"duration-special\", \"good-special\", \"direct_rad-special\", \"distant_rad-special\"\n",
    "]\n",
    "\n",
    "cols = [col for col in train_df.columns if \"A1\" in col or \"A2\" in col or \"A3\" in col or \"A4\" in col or \n",
    "        \"B1\" in col or \"B2\" in col or \"B3\" in col or \"B4\" in col]\n",
    "drop_cols = []\n",
    "for col1 in cols:\n",
    "    f = True\n",
    "    for col2 in num_cols:\n",
    "        if col2 in col1:\n",
    "            f = False\n",
    "    if f and train_df[col1].dtype in [int, float]:\n",
    "        drop_cols.append(col1)\n",
    "        \n",
    "train_df = train_df.drop(columns=drop_cols)\n",
    "test_df = test_df.drop(columns=drop_cols)\n",
    "        \n",
    "    \n",
    "\n",
    "train_df = prepro.add_numeric_info(train_df, num_cols)\n",
    "test_df = prepro.add_numeric_info(test_df, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 欠損値埋め先にやろう\n",
    "欠損値がある列\n",
    "\n",
    "rank, weapon, level ⇨　回線切れ or ナワバリ\n",
    "\n",
    "weaponの欠損に並んでそれに関係ある列、A3, A4, B3, B4 ⇨ 回線切れ\n",
    "\n",
    "level, weaponが消えていたら回線切れ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rankの欠損値を埋める\n",
    "train_df, test_df = prepro.fillna_rank(train_df, test_df)\n",
    "\n",
    "#そのほかの欠損値を埋める\n",
    "train_df, test_df = prepro.fillna(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum().sum())\n",
    "print(test_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリング\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reskin\n",
      "mainweapon\n",
      "subweapon\n",
      "special\n",
      "mizumashi\n"
     ]
    }
   ],
   "source": [
    "# count reskin, by mode\n",
    "print(\"reskin\")\n",
    "train_df, test_df = prepro.count_reskin(train_df, test_df)\n",
    "train_df, test_df = prepro.count_reskin_by_mode(train_df, test_df)\n",
    "\n",
    "# count mainweapon, by mode\n",
    "print(\"mainweapon\")\n",
    "train_df, test_df = prepro.count_mainweapon(train_df, test_df)\n",
    "train_df, test_df = prepro.count_mainweapon_by_mode(train_df, test_df)\n",
    "\n",
    "# count subweapon, by mode\n",
    "print(\"subweapon\")\n",
    "train_df, test_df = prepro.count_subweapon(train_df, test_df)\n",
    "train_df, test_df = prepro.count_subweapon_by_mode(train_df, test_df)\n",
    "\n",
    "# count special, by mode\n",
    "print(\"special\")\n",
    "train_df, test_df = prepro.count_special(train_df, test_df)\n",
    "train_df, test_df = prepro.count_special_by_mode(train_df, test_df)\n",
    "\n",
    "\n",
    "#identify A1\n",
    "train_df, test_df = prepro.identify_A1(train_df, test_df)\n",
    "\n",
    "\n",
    "# 水増し, A1も統計量に含めた特徴を作る場合は水ましより先にやる\n",
    "print(\"mizumashi\")\n",
    "train_df, y = prepro.mizumashi(train_df, y)\n",
    "\n",
    "# is_nawabari\n",
    "train_df, test_df = prepro.is_nawabari(train_df, test_df)\n",
    "\n",
    "# match rank、単体で意味なし\n",
    "train_df, test_df = prepro.match_rank(train_df, test_df)\n",
    "\n",
    "# rankを二列に分ける\n",
    "train_df, test_df = prepro.ranker(train_df, test_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160590, 608)\n",
      "special-A\n",
      "special-B\n",
      "subweapon-A\n",
      "subweapon-B\n",
      "category1-A\n",
      "category1-B\n",
      "category2-A\n",
      "category2-B\n",
      "(160590, 704)\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "# add team info、メインはなくてもいい\n",
    "\n",
    "#train_df,  test_df = prepro.addTeamInfo(train_df, test_df, cols=[\"special\", \"subweapon\", \"category1\", \"category2\", \"mainweapon\"])\n",
    "train_df,  test_df = prepro.addTeamInfo(train_df, test_df, cols=[\"special\", \"subweapon\", \"category1\", \"category2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category1\n",
      "category2\n",
      "subweapon\n",
      "special\n"
     ]
    }
   ],
   "source": [
    "# categorize team , 良い\n",
    "\n",
    "#categorize_col = [\"category1\", \"category2\", \"subweapon\", \"special\", \"mainweapon\"]\n",
    "categorize_col = [\"category1\", \"category2\", \"subweapon\", \"special\"]\n",
    "for col in categorize_col:\n",
    "    print(col)\n",
    "    train_df, test_df = prepro.categorize_team(train_df, test_df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プレイヤー固有のカテゴリ変数は個別にエンコードしなければいけないね…\n",
    "# rank\n",
    "# category1\n",
    "# category2\n",
    "# subweapon\n",
    "# special\n",
    "# mainweapon\n",
    "# reskin\n",
    "# mode x reskin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in [\"category1\", \"category2\", \"subweapon\", \"special\", \"mainweapon\", \"reskin\", ]:#\"mode x reskin\"]:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(train_df[col+\"-A4\"])\n",
    "    train_df[col+\"-A1\"] = lbl.transform(train_df[col+\"-A1\"])\n",
    "    train_df[col+\"-A2\"] = lbl.transform(train_df[col+\"-A2\"])\n",
    "    train_df[col+\"-A3\"] = lbl.transform(train_df[col+\"-A3\"])\n",
    "    train_df[col+\"-A4\"] = lbl.transform(train_df[col+\"-A4\"])\n",
    "    train_df[col+\"-B1\"] = lbl.transform(train_df[col+\"-B1\"])\n",
    "    train_df[col+\"-B2\"] = lbl.transform(train_df[col+\"-B2\"])\n",
    "    train_df[col+\"-B3\"] = lbl.transform(train_df[col+\"-B3\"])\n",
    "    train_df[col+\"-B4\"] = lbl.transform(train_df[col+\"-B4\"])\n",
    "    \n",
    "    test_df[col+\"-A1\"] = lbl.transform(test_df[col+\"-A1\"])\n",
    "    test_df[col+\"-A2\"] = lbl.transform(test_df[col+\"-A2\"])\n",
    "    test_df[col+\"-A3\"] = lbl.transform(test_df[col+\"-A3\"])\n",
    "    test_df[col+\"-A4\"] = lbl.transform(test_df[col+\"-A4\"])\n",
    "    test_df[col+\"-B1\"] = lbl.transform(test_df[col+\"-B1\"])\n",
    "    test_df[col+\"-B2\"] = lbl.transform(test_df[col+\"-B2\"])\n",
    "    test_df[col+\"-B3\"] = lbl.transform(test_df[col+\"-B3\"])\n",
    "    test_df[col+\"-B4\"] = lbl.transform(test_df[col+\"-B4\"])\n",
    "    \n",
    "for col in [\"rank-mark\", \"rank\"]:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(train_df[\"A4-\" + col])\n",
    "    train_df[\"A1-\"+col] = lbl.transform(train_df[\"A1-\"+col])\n",
    "    train_df[\"A2-\"+col] = lbl.transform(train_df[\"A2-\"+col])\n",
    "    train_df[\"A3-\"+col] = lbl.transform(train_df[\"A3-\"+col])\n",
    "    train_df[\"A4-\"+col] = lbl.transform(train_df[\"A4-\"+col])\n",
    "    train_df[\"B1-\"+col] = lbl.transform(train_df[\"B1-\"+col])\n",
    "    train_df[\"B2-\"+col] = lbl.transform(train_df[\"B2-\"+col])\n",
    "    train_df[\"B3-\"+col] = lbl.transform(train_df[\"B3-\"+col])\n",
    "    train_df[\"B4-\"+col] = lbl.transform(train_df[\"B4-\"+col])\n",
    "\n",
    "    test_df[\"A1-\"+col] = lbl.transform(test_df[\"A1-\"+col])\n",
    "    test_df[\"A2-\"+col] = lbl.transform(test_df[\"A2-\"+col])\n",
    "    test_df[\"A3-\"+col] = lbl.transform(test_df[\"A3-\"+col])\n",
    "    test_df[\"A4-\"+col] = lbl.transform(test_df[\"A4-\"+col])\n",
    "    test_df[\"B1-\"+col] = lbl.transform(test_df[\"B1-\"+col])\n",
    "    test_df[\"B2-\"+col] = lbl.transform(test_df[\"B2-\"+col])\n",
    "    test_df[\"B3-\"+col] = lbl.transform(test_df[\"B3-\"+col])\n",
    "    test_df[\"B4-\"+col] = lbl.transform(test_df[\"B4-\"+col])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# make input\n",
    "drop_cols = [\"id\", \"lobby\", \"lobby-mode\",  \"period\", \"game-ver\", \"A1-weapon\", \"A2-weapon\", \"A3-weapon\", \"A4-weapon\", \\\n",
    "              \"B1-weapon\", \"B2-weapon\", \"B3-weapon\", \"B4-weapon\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "categorical_feature = [col for col in train_df.dtypes[train_df.dtypes == \"object\"].index.to_list() if col not in drop_cols]\n",
    "\n",
    "X, test_X = prepro.make_input(train_df, test_df, drop_cols, categorical_encode=True, scaler=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132250, 699)\n",
      "(28340, 699)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "fold  1  size is  26450\n",
      "fold  2  size is  26450\n",
      "fold  3  size is  26450\n",
      "fold  4  size is  26450\n",
      "fold  5  size is  26450\n",
      "successfully split\n"
     ]
    }
   ],
   "source": [
    "# 全データを5つに分割\n",
    "random.seed(random.randint(0, 10000))\n",
    "SIZE = X.shape[0]\n",
    "K = 5\n",
    "\n",
    "\n",
    "#folds = prepro.make_stratified_kfolds(X, y, K, shuffle=True)\n",
    "folds = prepro.make_stratified_kfolds(X, X[\"mode\"].astype(str) + y.astype(str), K, shuffle=True, random_state=random.randint(0, 10000))\n",
    "\n",
    "\n",
    "print(len(folds))\n",
    "for i, fold in enumerate(folds):\n",
    "    print(\"fold \", i+1, \" size is \", len(fold))\n",
    "    \n",
    "    \n",
    "if SIZE != len(set(sum(folds, []))):\n",
    "    print(\"error is occuring in spliting\")\n",
    "else :\n",
    "    print(\"successfully split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== fold 1 ========================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.68819\n",
      "[200]\tvalid_0's binary_logloss: 0.685445\n",
      "[300]\tvalid_0's binary_logloss: 0.683946\n",
      "[400]\tvalid_0's binary_logloss: 0.68301\n",
      "[500]\tvalid_0's binary_logloss: 0.682462\n",
      "[600]\tvalid_0's binary_logloss: 0.682177\n",
      "[700]\tvalid_0's binary_logloss: 0.682057\n",
      "[800]\tvalid_0's binary_logloss: 0.681897\n",
      "[900]\tvalid_0's binary_logloss: 0.681772\n",
      "[1000]\tvalid_0's binary_logloss: 0.681742\n",
      "[1100]\tvalid_0's binary_logloss: 0.681648\n",
      "[1200]\tvalid_0's binary_logloss: 0.681619\n",
      "[1300]\tvalid_0's binary_logloss: 0.68158\n",
      "[1400]\tvalid_0's binary_logloss: 0.681552\n",
      "[1500]\tvalid_0's binary_logloss: 0.681477\n",
      "[1600]\tvalid_0's binary_logloss: 0.681488\n",
      "Early stopping, best iteration is:\n",
      "[1514]\tvalid_0's binary_logloss: 0.68147\n",
      "======================== fold 2 ========================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.687745\n",
      "[200]\tvalid_0's binary_logloss: 0.684995\n",
      "[300]\tvalid_0's binary_logloss: 0.6836\n",
      "[400]\tvalid_0's binary_logloss: 0.682724\n",
      "[500]\tvalid_0's binary_logloss: 0.68223\n",
      "[600]\tvalid_0's binary_logloss: 0.681968\n",
      "[700]\tvalid_0's binary_logloss: 0.681848\n",
      "[800]\tvalid_0's binary_logloss: 0.681739\n",
      "[900]\tvalid_0's binary_logloss: 0.681672\n",
      "[1000]\tvalid_0's binary_logloss: 0.681607\n",
      "[1100]\tvalid_0's binary_logloss: 0.681566\n",
      "[1200]\tvalid_0's binary_logloss: 0.681501\n",
      "[1300]\tvalid_0's binary_logloss: 0.681486\n",
      "[1400]\tvalid_0's binary_logloss: 0.681394\n",
      "[1500]\tvalid_0's binary_logloss: 0.681357\n",
      "[1600]\tvalid_0's binary_logloss: 0.681318\n",
      "[1700]\tvalid_0's binary_logloss: 0.68124\n",
      "[1800]\tvalid_0's binary_logloss: 0.681149\n",
      "[1900]\tvalid_0's binary_logloss: 0.68112\n",
      "[2000]\tvalid_0's binary_logloss: 0.681053\n",
      "Early stopping, best iteration is:\n",
      "[1990]\tvalid_0's binary_logloss: 0.681042\n",
      "======================== fold 3 ========================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.688289\n",
      "[200]\tvalid_0's binary_logloss: 0.685898\n",
      "[300]\tvalid_0's binary_logloss: 0.684409\n",
      "[400]\tvalid_0's binary_logloss: 0.683643\n",
      "[500]\tvalid_0's binary_logloss: 0.683105\n",
      "[600]\tvalid_0's binary_logloss: 0.682917\n",
      "[700]\tvalid_0's binary_logloss: 0.682773\n",
      "[800]\tvalid_0's binary_logloss: 0.68271\n",
      "[900]\tvalid_0's binary_logloss: 0.682625\n",
      "[1000]\tvalid_0's binary_logloss: 0.682595\n",
      "[1100]\tvalid_0's binary_logloss: 0.682509\n",
      "[1200]\tvalid_0's binary_logloss: 0.68245\n",
      "[1300]\tvalid_0's binary_logloss: 0.682418\n",
      "[1400]\tvalid_0's binary_logloss: 0.682399\n",
      "[1500]\tvalid_0's binary_logloss: 0.682316\n",
      "[1600]\tvalid_0's binary_logloss: 0.682313\n",
      "[1700]\tvalid_0's binary_logloss: 0.682337\n",
      "Early stopping, best iteration is:\n",
      "[1615]\tvalid_0's binary_logloss: 0.682286\n",
      "======================== fold 4 ========================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.687827\n",
      "[200]\tvalid_0's binary_logloss: 0.684961\n",
      "[300]\tvalid_0's binary_logloss: 0.683438\n",
      "[400]\tvalid_0's binary_logloss: 0.682664\n",
      "[500]\tvalid_0's binary_logloss: 0.682097\n",
      "[600]\tvalid_0's binary_logloss: 0.681827\n",
      "[700]\tvalid_0's binary_logloss: 0.681629\n",
      "[800]\tvalid_0's binary_logloss: 0.681419\n",
      "[900]\tvalid_0's binary_logloss: 0.681237\n",
      "[1000]\tvalid_0's binary_logloss: 0.681176\n",
      "[1100]\tvalid_0's binary_logloss: 0.681092\n",
      "[1200]\tvalid_0's binary_logloss: 0.681017\n",
      "[1300]\tvalid_0's binary_logloss: 0.680997\n",
      "[1400]\tvalid_0's binary_logloss: 0.680946\n",
      "[1500]\tvalid_0's binary_logloss: 0.68093\n",
      "[1600]\tvalid_0's binary_logloss: 0.680905\n",
      "[1700]\tvalid_0's binary_logloss: 0.680912\n",
      "Early stopping, best iteration is:\n",
      "[1643]\tvalid_0's binary_logloss: 0.680891\n",
      "======================== fold 5 ========================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.688077\n",
      "[200]\tvalid_0's binary_logloss: 0.68569\n",
      "[300]\tvalid_0's binary_logloss: 0.684363\n",
      "[400]\tvalid_0's binary_logloss: 0.683549\n",
      "[500]\tvalid_0's binary_logloss: 0.683131\n",
      "[600]\tvalid_0's binary_logloss: 0.682862\n",
      "[700]\tvalid_0's binary_logloss: 0.682708\n",
      "[800]\tvalid_0's binary_logloss: 0.682615\n",
      "[900]\tvalid_0's binary_logloss: 0.682406\n",
      "[1000]\tvalid_0's binary_logloss: 0.682283\n",
      "[1100]\tvalid_0's binary_logloss: 0.682203\n",
      "[1200]\tvalid_0's binary_logloss: 0.682102\n",
      "[1300]\tvalid_0's binary_logloss: 0.682085\n",
      "[1400]\tvalid_0's binary_logloss: 0.68208\n",
      "Early stopping, best iteration is:\n",
      "[1363]\tvalid_0's binary_logloss: 0.682051\n",
      "cv score :  0.5525746691871455\n",
      "cv ratio :  0.500937618147448\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    \"num_leaves\" : 28,\n",
    "    \"learning_rate\" : 0.01,\n",
    "    #\"learning_rate\" : 0.1,\n",
    "    \"num_iterations\" : 20000,\n",
    "    \"objective\" : \"binary\",\n",
    "    \"metric\" : [\"binary_logloss\"],\n",
    "    \"random_state\" : random.randint(0, 10000),\n",
    "    #\"random_state\" : 0,\n",
    "    #\"max_depth\" : 100\n",
    "}\n",
    "\n",
    "THRESHOLD = 0.50\n",
    "models = []\n",
    "cv_scores = []\n",
    "temp = 0\n",
    "train_pred = []\n",
    "train_Xs = []\n",
    "valid_Xs = []\n",
    "\n",
    "\n",
    "all_indices = sum(folds, [])\n",
    "for i in range(K):\n",
    "    print(\"======================== fold {} ========================\".format(i+1))\n",
    "    valid_indices = folds[i]\n",
    "    train_indices = list(set(all_indices) - set(valid_indices))\n",
    "    # print(\"train \", len(train_indices), \" , valid \", len(valid_indices))\n",
    "    train_X = X.iloc[train_indices]\n",
    "    try:\n",
    "        train_y = y.iloc[train_indices]\n",
    "    except:\n",
    "        train_y = y[train_indices]\n",
    "    valid_X = X.iloc[valid_indices]\n",
    "    try:\n",
    "        valid_y = y.iloc[valid_indices]\n",
    "    except:\n",
    "        valid_y = y[valid_indices]\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    train_data = lgb.Dataset(train_X, label=train_y)\n",
    "    valid_data = lgb.Dataset(valid_X, label=valid_y)\n",
    "\n",
    "    model = lgb.train(\n",
    "        param, \n",
    "        train_data, \n",
    "        valid_sets=valid_data, \n",
    "        #categorical_feature=categorical_feature,\n",
    "        early_stopping_rounds=100, \n",
    "        verbose_eval=100,\n",
    "        \n",
    "    )\n",
    "    pred = model.predict(valid_X)\n",
    "    pred = np.where(pred < THRESHOLD, 0, 1)\n",
    "    train_pred.append(pred)\n",
    "    temp += np.sum(pred)\n",
    "    \n",
    "    score = accuracy_score(pred, valid_y)\n",
    "    \n",
    "    models.append(model)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    \n",
    "print(\"cv score : \", np.mean(cv_scores))    \n",
    "print(\"cv ratio : \", temp / SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5107949598420383\n",
      "0.5110060988184605\n",
      "0.5120378702699909\n",
      "0.5107261461584807\n",
      "0.5112437695856259\n",
      "0.5111617689349193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'pred'}>]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "        \n",
    "for i in range(K):\n",
    "    model = models[i]\n",
    "    pred = model.predict(test_X)\n",
    "    preds.append(pred)\n",
    "    print(np.sum(pred) / pred.shape[0])\n",
    "    \n",
    "preds = np.array(preds)\n",
    "preds = np.mean(preds, axis=0)\n",
    "print(np.sum(preds) / preds.shape[0])\n",
    "\n",
    "\n",
    "temp = pd.DataFrame({\"pred\":pred})\n",
    "temp.hist(bins=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5742413549752999\n"
     ]
    }
   ],
   "source": [
    "preds_ = np.where(preds < THRESHOLD, 0, 1)\n",
    "print(np.sum(preds_) / preds_.shape[0])\n",
    "\n",
    "submit_df = pd.DataFrame({'y': preds_})\n",
    "submit_df.index.name = 'id'\n",
    "submit_df.to_csv('../Submissions/submission13_psd1_{}.csv'.format(K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_X[\"pred\"] = preds\n",
    "test_X[\"y\"] = preds_\n",
    "ps_X = pd.concat([X, test_X[np.abs(0.5-test_X[\"pred\"]) > 0.25]])\n",
    "ps_y = np.append(y, test_X[\"y\"][np.abs(0.5-test_X[\"pred\"]) > 0.25].values)\n",
    "\n",
    "\n",
    "\n",
    "test_X.drop(columns=[\"pred\"], inplace=True)\n",
    "test_X.drop(columns=[\"y\"], inplace=True)\n",
    "ps_X.drop(columns=[\"pred\"], inplace=True)\n",
    "ps_X.drop(columns=[\"y\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "fold  1  size is  26479\n",
      "fold  2  size is  26479\n",
      "fold  3  size is  26479\n",
      "fold  4  size is  26478\n",
      "fold  5  size is  26478\n",
      "successfully split\n"
     ]
    }
   ],
   "source": [
    "# 全データを5つに分割\n",
    "SIZE = ps_X.shape[0]\n",
    "K = 5\n",
    "\n",
    "\n",
    "#folds = prepro.make_stratified_kfolds(X, y, K, shuffle=True)\n",
    "folds = prepro.make_stratified_kfolds(ps_X, ps_X[\"mode\"].astype(str) + ps_y.astype(str), K, shuffle=True, random_state=random.randint(0, 10000))\n",
    "\n",
    "\n",
    "print(len(folds))\n",
    "for i, fold in enumerate(folds):\n",
    "    print(\"fold \", i+1, \" size is \", len(fold))\n",
    "    \n",
    "    \n",
    "if SIZE != len(set(sum(folds, []))):\n",
    "    print(\"error is occuring in spliting\")\n",
    "else :\n",
    "    print(\"successfully split\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== fold 1 ========================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.687808\n",
      "[200]\tvalid_0's binary_logloss: 0.685106\n",
      "[300]\tvalid_0's binary_logloss: 0.683742\n",
      "[400]\tvalid_0's binary_logloss: 0.68287\n",
      "[500]\tvalid_0's binary_logloss: 0.682463\n",
      "[600]\tvalid_0's binary_logloss: 0.682355\n",
      "[700]\tvalid_0's binary_logloss: 0.682201\n",
      "[800]\tvalid_0's binary_logloss: 0.682076\n",
      "[900]\tvalid_0's binary_logloss: 0.68205\n",
      "[1000]\tvalid_0's binary_logloss: 0.681977\n",
      "[1100]\tvalid_0's binary_logloss: 0.681901\n",
      "[1200]\tvalid_0's binary_logloss: 0.681826\n",
      "[1300]\tvalid_0's binary_logloss: 0.681825\n",
      "[1400]\tvalid_0's binary_logloss: 0.681782\n",
      "[1500]\tvalid_0's binary_logloss: 0.681783\n",
      "[1600]\tvalid_0's binary_logloss: 0.68171\n",
      "[1700]\tvalid_0's binary_logloss: 0.681667\n",
      "[1800]\tvalid_0's binary_logloss: 0.681614\n",
      "[1900]\tvalid_0's binary_logloss: 0.681563\n",
      "[2000]\tvalid_0's binary_logloss: 0.681592\n",
      "Early stopping, best iteration is:\n",
      "[1935]\tvalid_0's binary_logloss: 0.681545\n",
      "======================== fold 2 ========================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.68771\n",
      "[200]\tvalid_0's binary_logloss: 0.684906\n",
      "[300]\tvalid_0's binary_logloss: 0.683348\n",
      "[400]\tvalid_0's binary_logloss: 0.682424\n",
      "[500]\tvalid_0's binary_logloss: 0.681811\n",
      "[600]\tvalid_0's binary_logloss: 0.681557\n",
      "[700]\tvalid_0's binary_logloss: 0.681339\n",
      "[800]\tvalid_0's binary_logloss: 0.68123\n",
      "[900]\tvalid_0's binary_logloss: 0.681101\n",
      "[1000]\tvalid_0's binary_logloss: 0.680963\n",
      "[1100]\tvalid_0's binary_logloss: 0.680939\n",
      "[1200]\tvalid_0's binary_logloss: 0.680858\n",
      "[1300]\tvalid_0's binary_logloss: 0.680736\n",
      "[1400]\tvalid_0's binary_logloss: 0.680649\n",
      "[1500]\tvalid_0's binary_logloss: 0.680624\n",
      "[1600]\tvalid_0's binary_logloss: 0.68058\n",
      "[1700]\tvalid_0's binary_logloss: 0.68058\n",
      "Early stopping, best iteration is:\n",
      "[1618]\tvalid_0's binary_logloss: 0.680544\n",
      "======================== fold 3 ========================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.687574\n",
      "[200]\tvalid_0's binary_logloss: 0.684946\n",
      "[300]\tvalid_0's binary_logloss: 0.683487\n",
      "[400]\tvalid_0's binary_logloss: 0.682619\n",
      "[500]\tvalid_0's binary_logloss: 0.682144\n",
      "[600]\tvalid_0's binary_logloss: 0.681957\n",
      "[700]\tvalid_0's binary_logloss: 0.681814\n",
      "[800]\tvalid_0's binary_logloss: 0.681736\n",
      "[900]\tvalid_0's binary_logloss: 0.68168\n",
      "[1000]\tvalid_0's binary_logloss: 0.681625\n",
      "[1100]\tvalid_0's binary_logloss: 0.681523\n",
      "[1200]\tvalid_0's binary_logloss: 0.681508\n",
      "[1300]\tvalid_0's binary_logloss: 0.681485\n",
      "[1400]\tvalid_0's binary_logloss: 0.681535\n",
      "Early stopping, best iteration is:\n",
      "[1301]\tvalid_0's binary_logloss: 0.681477\n",
      "======================== fold 4 ========================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.687612\n",
      "[200]\tvalid_0's binary_logloss: 0.684603\n",
      "[300]\tvalid_0's binary_logloss: 0.683045\n",
      "[400]\tvalid_0's binary_logloss: 0.682276\n",
      "[500]\tvalid_0's binary_logloss: 0.681744\n",
      "[600]\tvalid_0's binary_logloss: 0.681467\n",
      "[700]\tvalid_0's binary_logloss: 0.681206\n",
      "[800]\tvalid_0's binary_logloss: 0.681026\n",
      "[900]\tvalid_0's binary_logloss: 0.680882\n",
      "[1000]\tvalid_0's binary_logloss: 0.680749\n",
      "[1100]\tvalid_0's binary_logloss: 0.680745\n",
      "[1200]\tvalid_0's binary_logloss: 0.680684\n",
      "[1300]\tvalid_0's binary_logloss: 0.680654\n",
      "[1400]\tvalid_0's binary_logloss: 0.680589\n",
      "[1500]\tvalid_0's binary_logloss: 0.680578\n",
      "Early stopping, best iteration is:\n",
      "[1468]\tvalid_0's binary_logloss: 0.680567\n",
      "======================== fold 5 ========================\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.687785\n",
      "[200]\tvalid_0's binary_logloss: 0.684894\n",
      "[300]\tvalid_0's binary_logloss: 0.683427\n",
      "[400]\tvalid_0's binary_logloss: 0.682475\n",
      "[500]\tvalid_0's binary_logloss: 0.682047\n",
      "[600]\tvalid_0's binary_logloss: 0.681752\n",
      "[700]\tvalid_0's binary_logloss: 0.681613\n",
      "[800]\tvalid_0's binary_logloss: 0.681572\n",
      "[900]\tvalid_0's binary_logloss: 0.681458\n",
      "[1000]\tvalid_0's binary_logloss: 0.681401\n",
      "[1100]\tvalid_0's binary_logloss: 0.68132\n",
      "[1200]\tvalid_0's binary_logloss: 0.681273\n",
      "[1300]\tvalid_0's binary_logloss: 0.681185\n",
      "[1400]\tvalid_0's binary_logloss: 0.681145\n",
      "[1500]\tvalid_0's binary_logloss: 0.681109\n",
      "[1600]\tvalid_0's binary_logloss: 0.681084\n",
      "[1700]\tvalid_0's binary_logloss: 0.681084\n",
      "Early stopping, best iteration is:\n",
      "[1659]\tvalid_0's binary_logloss: 0.681056\n",
      "cv score :  0.5543797516604796\n",
      "cv ratio :  0.5003167902034317\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    \"num_leaves\" : 28,\n",
    "    \"learning_rate\" : 0.01,\n",
    "    #\"learning_rate\" : 0.1,\n",
    "    \"num_iterations\" : 20000,\n",
    "    \"objective\" : \"binary\",\n",
    "    \"metric\" : [\"binary_logloss\"],\n",
    "    \"random_state\" : random.randint(0, 10000),\n",
    "    #\"random_state\" : 0,\n",
    "    #\"max_depth\" : 100\n",
    "}\n",
    "\n",
    "THRESHOLD = 0.50\n",
    "models = []\n",
    "cv_scores = []\n",
    "temp = 0\n",
    "train_pred = []\n",
    "train_Xs = []\n",
    "valid_Xs = []\n",
    "\n",
    "\n",
    "all_indices = sum(folds, [])\n",
    "for i in range(K):\n",
    "    print(\"======================== fold {} ========================\".format(i+1))\n",
    "    valid_indices = folds[i]\n",
    "    train_indices = list(set(all_indices) - set(valid_indices))\n",
    "    train_X = ps_X.iloc[train_indices]\n",
    "    try:\n",
    "        train_y = ps_y.iloc[train_indices]\n",
    "    except:\n",
    "        train_y = ps_y[train_indices]\n",
    "    valid_X = ps_X.iloc[valid_indices]\n",
    "    try:\n",
    "        valid_y = ps_y.iloc[valid_indices]\n",
    "    except:\n",
    "        valid_y = ps_y[valid_indices]\n",
    "    \n",
    "        \n",
    "    train_data = lgb.Dataset(train_X, label=train_y)\n",
    "    valid_data = lgb.Dataset(valid_X, label=valid_y)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        param, \n",
    "        train_data, \n",
    "        valid_sets=valid_data, \n",
    "        #categorical_feature=categorical_feature,\n",
    "        early_stopping_rounds=100, \n",
    "        verbose_eval=100,\n",
    "        \n",
    "    )\n",
    "    pred = model.predict(valid_X)\n",
    "    \n",
    "    train_pred.append(pred)\n",
    "    temp += np.sum(pred)\n",
    "    pred = np.where(pred < THRESHOLD, 0, 1)\n",
    "    score = accuracy_score(pred, valid_y)\n",
    "    \n",
    "    models.append(model)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    \n",
    "print(\"cv score : \", np.mean(cv_scores))    \n",
    "print(\"cv ratio : \", temp / SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5117321534647411\n",
      "0.5111221545132362\n",
      "0.5115910754167764\n",
      "0.5106045977112518\n",
      "0.5118396121433655\n",
      "0.5113779186498741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'pred'}>]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "for i in range(K):\n",
    "    model = models[i]\n",
    "    pred = model.predict(test_X)\n",
    "    preds.append(pred)\n",
    "    print(np.sum(pred) / pred.shape[0])\n",
    "    \n",
    "preds = np.array(preds)\n",
    "preds = np.mean(preds, axis=0)\n",
    "print(np.sum(preds) / preds.shape[0])\n",
    "\n",
    "\n",
    "temp = pd.DataFrame({\"pred\":pred})\n",
    "temp.hist(bins=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.571347918136909\n"
     ]
    }
   ],
   "source": [
    "preds_ = np.where(preds < THRESHOLD, 0, 1)\n",
    "print(np.sum(preds_) / preds_.shape[0])\n",
    "\n",
    "submit_df = pd.DataFrame({'y': preds_})\n",
    "submit_df.index.name = 'id'\n",
    "submit_df.to_csv('../Submissions/submission13_psd3_{}.csv'.format(K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル解釈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(models[0].feature_importance(), index=train_Xs[0].columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "display(importance.iloc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [index for index in importance.index if \"A1\" in index]\n",
    "importance.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [index for index in importance.index if \"range-sub\" in index]\n",
    "importance.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance[\"importance\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"pred\"] = 0\n",
    "train_df[\"y\"] = y\n",
    "for i in range(K):\n",
    "    train_df[\"pred\"].iloc[folds[i]] = train_pred[i]\n",
    "for mode in train_df[\"mode\"].unique():\n",
    "    rate = train_df[train_df[\"mode\"] == mode][train_df[\"pred\"] == train_df[\"y\"]].shape[0] / train_df[train_df[\"mode\"] == mode].shape[0]\n",
    "    print(\"{} : {}\".format(mode, rate))\n",
    "print(train_df[train_df[\"pred\"] == train_df[\"y\"]].shape[0] / train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_df[train_df[\"y\"] != train_df[\"pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"../../data/result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df[train_df[\"mode\"] == \"nawabari\"].shape[0]/train_df.shape[0])\n",
    "print(train_df[train_df[\"mode\"] == \"hoko\"].shape[0]/train_df.shape[0])\n",
    "print(train_df[train_df[\"mode\"] == \"asari\"].shape[0]/train_df.shape[0])\n",
    "print(train_df[train_df[\"mode\"] == \"area\"].shape[0]/train_df.shape[0])\n",
    "print(train_df[train_df[\"mode\"] == \"yagura\"].shape[0]/train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df[result_df[\"mode\"] == \"nawabari\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"hoko\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"asari\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"area\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"yagura\"].shape[0]/result_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_ = [\n",
    "    \"range-main\", \"range-bullet-main\", \"range-draw-main\", \"direct_range-sub\", \"distant-range_sub\", \n",
    "    \"rapid\", \"atack\", \"ink-sub\", \"fav-main\", \"good-special\", \"DPS\", \"kill_time_human-main\", \"kill_time_ika-main\",\n",
    "    \"front_gap_human-main\", \"front_gap_ika-main\", \"rensya_frame-main\", \"saidai_damege-main\", \"damage_min-sub\", \n",
    "    \"damage_max-sub\", \"install_num-sub\", \"good-sub\", \"direct_range-sub\", \"damage_max-special\", \n",
    "    \"damage_min-special\", \"duration-special\", \"good-special\", \"direct_rad-special\", \"close_rad-special\", \"distant_rad-special\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = []\n",
    "for name in num_cols_:\n",
    "    for col in X.columns:\n",
    "        if name in col:\n",
    "            feature_cols.append(col)\n",
    "                \n",
    "importance.loc[feature_cols]#.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = []\n",
    "\n",
    "\"\"\"\n",
    "A-direct_range-sub-mean 30\n",
    "A-distant_range_sub-max\n",
    "B-rapid-std\t52\n",
    "ink-sub\n",
    "A-kill_time_human-main-median\t36\n",
    "A-kill_time_ika-main-median\t58\n",
    "A-front_gap_human-main-std\t25\n",
    "A-front_gap_ika-main-std\t48\n",
    "A-saidai_damege-main-mean\t40\n",
    "damage_max-sub 37\n",
    "install_num-sub 10\n",
    "direct_range-sub 30\n",
    "damage_max-special 47\n",
    "duration-special 46\n",
    "close_rad-special 30\n",
    "distant_rad-special 21\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for col in X.columns:\n",
    "    if \"distant_rad-special\" in col:\n",
    "        sss.append(col)\n",
    "                \n",
    "importance.loc[sss].sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"y\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reskin_g = pd.concat([\n",
    "    #train_df[[\"reskin-A1\", \"y\"]].rename(columns={\"reskin-A1\" : \"reskin\"}), \n",
    "    train_df[[\"reskin-A2\", \"y\"]].rename(columns={\"reskin-A2\" : \"reskin\"}), \n",
    "    train_df[[\"reskin-A3\", \"y\"]].rename(columns={\"reskin-A3\" : \"reskin\"}), \n",
    "    train_df[[\"reskin-A4\", \"y\"]].rename(columns={\"reskin-A4\" : \"reskin\"}),\n",
    "    pd.concat([train_df[\"reskin-B1\"], train_df[\"y\"].apply(lambda x : 1-x)], axis=1).rename(columns={\"reskin-B1\" : \"reskin\"}),\n",
    "    pd.concat([train_df[\"reskin-B2\"], train_df[\"y\"].apply(lambda x : 1-x)], axis=1).rename(columns={\"reskin-B2\" : \"reskin\"}),\n",
    "    pd.concat([train_df[\"reskin-B3\"], train_df[\"y\"].apply(lambda x : 1-x)], axis=1).rename(columns={\"reskin-B3\" : \"reskin\"}),\n",
    "    pd.concat([train_df[\"reskin-B4\"], train_df[\"y\"].apply(lambda x : 1-x)], axis=1).rename(columns={\"reskin-B4\" : \"reskin\"}),\n",
    "],axis=0, ignore_index=True).groupby(\"reskin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rate = reskin_g.sum() / reskin_g.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapon = pd.concat([\n",
    "    #train_df[[\"weapon-A1\", \"y\"]].rename(columns={\"weapon-A1\" : \"weapon\"}), \n",
    "    train_df[[\"A2-weapon\", \"y\"]].rename(columns={\"A2-weapon\" : \"weapon\"}), \n",
    "    train_df[[\"A3-weapon\", \"y\"]].rename(columns={\"A3-weapon\" : \"weapon\"}), \n",
    "    train_df[[\"A4-weapon\", \"y\"]].rename(columns={\"A4-weapon\" : \"weapon\"}),\n",
    "    pd.concat([train_df[\"B1-weapon\"], train_df[\"y\"].apply(lambda x : 1-x)], axis=1).rename(columns={\"B1-weapon\" : \"weapon\"}),\n",
    "    pd.concat([train_df[\"B2-weapon\"], train_df[\"y\"].apply(lambda x : 1-x)], axis=1).rename(columns={\"B2-weapon\" : \"weapon\"}),\n",
    "    pd.concat([train_df[\"B3-weapon\"], train_df[\"y\"].apply(lambda x : 1-x)], axis=1).rename(columns={\"B3-weapon\" : \"weapon\"}),\n",
    "    pd.concat([train_df[\"B4-weapon\"], train_df[\"y\"].apply(lambda x : 1-x)], axis=1).rename(columns={\"B4-weapon\" : \"weapon\"}),\n",
    "],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rate = (weapon.groupby(\"weapon\").sum() / weapon.groupby(\"weapon\").count()).sort_values(\"y\", ascending=False)\n",
    "win_rate.loc[\"bold_7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
