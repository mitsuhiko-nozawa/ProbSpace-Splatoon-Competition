{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM Model\n",
    "#### cv score :  0.5502911153119092 (5 folds, tgt enc)\n",
    "#### cv score :  0.5534669187145557 (5fold)\n",
    "#### cv score :  0.5534489970795226 (5 even fold)\n",
    "#### cv score :  0.5507674858223063   (10 folds)\n",
    "#### cv score :  0.5539240004577335   (5 even folds, nomizumahi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from Functions import prepro\n",
    "import warnings\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "FEATURE_SELECTION = False\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 600)\n",
    "pd.set_option(\"display.max_rows\", 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66125, 304)\n",
      "(28340, 303)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../../data/Processed/train2.csv\")\n",
    "test_df = pd.read_csv(\"../../data/Processed/test2.csv\")\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[\"y\"].values\n",
    "train_df = train_df.drop(\"y\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add disconnection info\n",
    "\n",
    "train_df = prepro.add_disconnection(train_df)\n",
    "test_df = prepro.add_disconnection(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add info about numeric column\n",
    "# 武器データの中のnum_colsを持つ特徴について、チーム内の統計量を計算、levelは結構効いてる\n",
    "\n",
    "num_cols = [\n",
    "    \"level\", \"range-main\", \"range-bullet-main\", \"range-draw-main\", \"direct_range-sub\", \"distant-range_sub\", \n",
    "    \"rapid\", \"atack\", \"ink-sub\", \"fav-main\", \"good-special\", \"DPS\", \"kill_time_human-main\", \"kill_time_ika-main\",\n",
    "    \"front_gap_human-main\", \"front_gap_ika-main\", \"rensya_frame-main\", \"saidai_damege-main\", \"damage_min-sub\", \n",
    "    \"damage_max-sub\", \"install_num-sub\", \"good-sub\", \"direct_range-sub\", \"distant-range_sub\", \"damage_max-special\", \n",
    "    \"damage_min-special\", \"duration-special\", \"good-special\", \"direct_rad-special\", \"close_rad-special\", \"distant_rad-special\"\n",
    "]\n",
    "\n",
    "#train_df = prepro.flat(train_df, num_cols)\n",
    "#test_df = prepro.flat(test_df, num_cols)\n",
    "\n",
    "train_df = prepro.add_numeric_info(train_df, num_cols)\n",
    "test_df = prepro.add_numeric_info(test_df, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 欠損値埋め先にやろう\n",
    "欠損値がある列\n",
    "\n",
    "rank, weapon, level ⇨　回線切れ or ナワバリ\n",
    "\n",
    "weaponの欠損に並んでそれに関係ある列、A3, A4, B3, B4 ⇨ 回線切れ\n",
    "\n",
    "level, weaponが消えていたら回線切れ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rankの欠損値を埋める\n",
    "train_df, test_df = prepro.fillna_rank(train_df, test_df)\n",
    "\n",
    "#そのほかの欠損値を埋める\n",
    "train_df, test_df = prepro.fillna(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum().sum())\n",
    "print(test_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリング\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reskin\n",
      "mainweapon\n",
      "subweapon\n",
      "special\n"
     ]
    }
   ],
   "source": [
    "# count reskin, by mode\n",
    "print(\"reskin\")\n",
    "train_df, test_df = prepro.count_reskin(train_df, test_df)\n",
    "train_df, test_df = prepro.count_reskin_by_mode(train_df, test_df)\n",
    "\n",
    "# count mainweapon, by mode\n",
    "print(\"mainweapon\")\n",
    "train_df, test_df = prepro.count_mainweapon(train_df, test_df)\n",
    "train_df, test_df = prepro.count_mainweapon_by_mode(train_df, test_df)\n",
    "\n",
    "# count subweapon, by mode\n",
    "print(\"subweapon\")\n",
    "train_df, test_df = prepro.count_subweapon(train_df, test_df)\n",
    "train_df, test_df = prepro.count_subweapon_by_mode(train_df, test_df)\n",
    "\n",
    "# count special, by mode\n",
    "print(\"special\")\n",
    "train_df, test_df = prepro.count_special(train_df, test_df)\n",
    "train_df, test_df = prepro.count_special_by_mode(train_df, test_df)\n",
    "\n",
    "#identify A1\n",
    "train_df, test_df = prepro.identify_A1(train_df, test_df)\n",
    "\n",
    "\n",
    "# 水増し, A1も統計量に含めた特徴を作る場合は水ましより先にやる\n",
    "train_df, y = prepro.mizumashi(train_df, y)\n",
    "\n",
    "# is_nawabari\n",
    "train_df, test_df = prepro.is_nawabari(train_df, test_df)\n",
    "\n",
    "# match rank\n",
    "train_df, test_df = prepro.match_rank(train_df, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160590, 708)\n",
      "special-A\n",
      "special-B\n",
      "subweapon-A\n",
      "subweapon-B\n",
      "category1-A\n",
      "category1-B\n",
      "category2-A\n",
      "category2-B\n",
      "mainweapon-A\n",
      "mainweapon-B\n",
      "(160590, 902)\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "# add team info\n",
    "\n",
    "train_df,  test_df = prepro.addTeamInfo(train_df, test_df, cols=[\"special\", \"subweapon\", \"category1\", \"category2\", \"mainweapon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category1\n",
      "category2\n",
      "subweapon\n",
      "special\n",
      "mainweapon\n"
     ]
    }
   ],
   "source": [
    "# categorize team\n",
    "\n",
    "categorize_col = [\"category1\", \"category2\", \"subweapon\", \"special\", \"mainweapon\"]\n",
    "for col in categorize_col:\n",
    "    print(col)\n",
    "    train_df_, test_df_ = prepro.categorize_team(train_df, test_df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product categorical feature\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"stage\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-category1-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-category1-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-category2-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-category2-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-mainweapon-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-mainweapon-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-subweapon-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-subweapon-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-special-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-special-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"match_rank\")\n",
    "\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-category1-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-category1-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-category2-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-category2-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-mainweapon-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-mainweapon-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-subweapon-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-subweapon-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-special-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-special-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"match_rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# make input\n",
    "\n",
    "drop_cols = [\"id\", \"lobby\", \"lobby-mode\",  \"period\", \"game-ver\", \"A1-weapon\", \"A2-weapon\", \"A3-weapon\", \"A4-weapon\", \\\n",
    "              \"B1-weapon\", \"B2-weapon\", \"B3-weapon\", \"B4-weapon\"]\n",
    "\n",
    "categorical_feature = [col for col in train_df.dtypes[train_df.dtypes == \"object\"].index.to_list() if col not in drop_cols]\n",
    "\n",
    "X, test_X = prepro.make_input(train_df, test_df, drop_cols, categorical_encode=True, scaler=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop_cols = [col for col in X.columns if \"onehot\" in col]\n",
    "#X = X.drop(columns=drop_cols)\n",
    "#test_X = test_X.drop(columns=drop_cols)\n",
    "#cols = [col for col in X.columns if (\"A1\" in col or \"A2\" in col or \"A3\" in col or \"A4\" in col\n",
    "#        or \"B1\" in col or \"B2\" in col or \"B3\" in col or \"B4\" in col )and \"count\" not in col]\n",
    "#X = X.drop(columns=cols)\n",
    "#test_X = test_X.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レベル落とす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132250, 922)\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [\"A1-level\", \"A2-level\", \"A3-level\", \"A4-level\", \"B1-level\", \"B2-level\", \"B3-level\", \"B4-level\"]\n",
    "X = X.drop(columns=drop_cols)\n",
    "test_X = test_X.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132250, 922)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 特徴選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FEATURE_SELECTION:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X, y)\n",
    "    importance = pd.DataFrame(clf.feature_importances_, index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "    display(importance*10000)\n",
    "    use_cols = importance.index[:450]\n",
    "else:\n",
    "    print(\"No feature selection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "successfully split\n",
      "======================== fold 1 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681944\n",
      "Early stopping, best iteration is:\n",
      "[1047]\tvalid_0's binary_logloss: 0.681921\n",
      "======================== fold 2 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681809\n",
      "Early stopping, best iteration is:\n",
      "[1192]\tvalid_0's binary_logloss: 0.681631\n",
      "======================== fold 3 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681699\n",
      "Early stopping, best iteration is:\n",
      "[1055]\tvalid_0's binary_logloss: 0.681667\n",
      "======================== fold 4 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.682316\n",
      "Early stopping, best iteration is:\n",
      "[1031]\tvalid_0's binary_logloss: 0.682263\n",
      "======================== fold 5 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681336\n",
      "Early stopping, best iteration is:\n",
      "[1038]\tvalid_0's binary_logloss: 0.681288\n",
      "cv score :  0.5540331820260717\n",
      "cv ratio :  0.5022003780718336\n",
      "0.5103644100519338\n",
      "0.5110926397653145\n",
      "0.5104898275262494\n",
      "0.5102145919008555\n",
      "0.5103902430837148\n",
      "iteration 2\n",
      "successfully split\n",
      "======================== fold 1 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.682189\n",
      "Early stopping, best iteration is:\n",
      "[1228]\tvalid_0's binary_logloss: 0.682016\n",
      "======================== fold 2 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[646]\tvalid_0's binary_logloss: 0.683976\n",
      "======================== fold 3 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.680796\n",
      "Early stopping, best iteration is:\n",
      "[1018]\tvalid_0's binary_logloss: 0.680766\n",
      "======================== fold 4 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681549\n",
      "Early stopping, best iteration is:\n",
      "[1071]\tvalid_0's binary_logloss: 0.681516\n",
      "======================== fold 5 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681548\n",
      "Early stopping, best iteration is:\n",
      "[1043]\tvalid_0's binary_logloss: 0.681516\n",
      "cv score :  0.5531282500508764\n",
      "cv ratio :  0.5003024574669187\n",
      "0.5104456473984694\n",
      "0.5102776178989484\n",
      "0.5104206943731685\n",
      "0.5106535637494569\n",
      "0.5104843958826113\n",
      "iteration 3\n",
      "successfully split\n",
      "======================== fold 1 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[946]\tvalid_0's binary_logloss: 0.681918\n",
      "======================== fold 2 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681897\n",
      "Early stopping, best iteration is:\n",
      "[1066]\tvalid_0's binary_logloss: 0.681795\n",
      "======================== fold 3 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[734]\tvalid_0's binary_logloss: 0.682478\n",
      "======================== fold 4 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.682424\n",
      "Early stopping, best iteration is:\n",
      "[999]\tvalid_0's binary_logloss: 0.682422\n",
      "======================== fold 5 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681058\n",
      "Early stopping, best iteration is:\n",
      "[1079]\tvalid_0's binary_logloss: 0.681015\n",
      "cv score :  0.5527959308051733\n",
      "cv ratio :  0.4988506616257089\n",
      "0.5102929424750238\n",
      "0.5102199593700754\n",
      "0.5101168295654812\n",
      "0.5100547250021982\n",
      "0.5103643797398397\n",
      "iteration 4\n",
      "successfully split\n",
      "======================== fold 1 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[946]\tvalid_0's binary_logloss: 0.683055\n",
      "======================== fold 2 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681169\n",
      "Early stopping, best iteration is:\n",
      "[1118]\tvalid_0's binary_logloss: 0.681047\n",
      "======================== fold 3 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[828]\tvalid_0's binary_logloss: 0.682325\n",
      "======================== fold 4 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[831]\tvalid_0's binary_logloss: 0.681918\n",
      "======================== fold 5 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681974\n",
      "Early stopping, best iteration is:\n",
      "[1154]\tvalid_0's binary_logloss: 0.681879\n",
      "cv score :  0.5522718272968917\n",
      "cv ratio :  0.499538752362949\n",
      "0.5102681823173558\n",
      "0.5105297436954718\n",
      "0.5107199307660458\n",
      "0.509967937191432\n",
      "0.5102300751084927\n",
      "iteration 5\n",
      "successfully split\n",
      "======================== fold 1 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681371\n",
      "Early stopping, best iteration is:\n",
      "[1252]\tvalid_0's binary_logloss: 0.681137\n",
      "======================== fold 2 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.682772\n",
      "Early stopping, best iteration is:\n",
      "[1354]\tvalid_0's binary_logloss: 0.682539\n",
      "======================== fold 3 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681378\n",
      "Early stopping, best iteration is:\n",
      "[967]\tvalid_0's binary_logloss: 0.681338\n",
      "======================== fold 4 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.682376\n",
      "Early stopping, best iteration is:\n",
      "[1071]\tvalid_0's binary_logloss: 0.682244\n",
      "======================== fold 5 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681667\n",
      "Early stopping, best iteration is:\n",
      "[1408]\tvalid_0's binary_logloss: 0.681378\n",
      "cv score :  0.5532939007248932\n",
      "cv ratio :  0.5009754253308129\n",
      "0.5108184009774384\n",
      "0.5112575461627887\n",
      "0.5097913019702086\n",
      "0.5107101108524311\n",
      "0.5108086524303417\n",
      "iteration 6\n",
      "successfully split\n",
      "======================== fold 1 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.681023\n",
      "Early stopping, best iteration is:\n",
      "[1241]\tvalid_0's binary_logloss: 0.680875\n",
      "======================== fold 2 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.682211\n",
      "Early stopping, best iteration is:\n",
      "[1019]\tvalid_0's binary_logloss: 0.682181\n",
      "======================== fold 3 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[939]\tvalid_0's binary_logloss: 0.682847\n",
      "======================== fold 4 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[857]\tvalid_0's binary_logloss: 0.681873\n",
      "======================== fold 5 ========================\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[750]\tvalid_0's binary_logloss: 0.68221\n",
      "cv score :  0.5536498625971185\n",
      "cv ratio :  0.5016862003780719\n",
      "0.5109501351476154\n",
      "0.5106704152338337\n",
      "0.5103424470180185\n",
      "0.5103237266803318\n",
      "0.5097572413152227\n",
      "iteration 7\n",
      "successfully split\n",
      "======================== fold 1 ========================\n"
     ]
    }
   ],
   "source": [
    "cvs = []\n",
    "train_pred_features = []\n",
    "test_pred_features = []\n",
    "\n",
    "for _ in range(10):\n",
    "    print(\"iteration {}\".format(_+1))\n",
    "    \n",
    "    # 全データを5つに分割\n",
    "    random.seed(random.randint(0, 10000))\n",
    "    SIZE = X.shape[0]\n",
    "    K = 5\n",
    "    cat_tgtenc_cols = [\"mode\", \"stage\", \"team-category1-A\", \"team-category1-B\"]\n",
    "    #cat_tgtenc_cols = [\"mode\", \"stage\"]\n",
    "\n",
    "    # folds = prepro.make_kfolds(SIZE, K)\n",
    "    #folds = prepro.make_stratified_kfolds(X, y, K)\n",
    "    folds = prepro.make_even_kfolds(X, y, K)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SIZE != len(set(sum(folds, []))):\n",
    "        print(\"error is occuring in spliting\")\n",
    "    else :\n",
    "        print(\"successfully split\")\n",
    "\n",
    "    if FEATURE_SELECTION:\n",
    "        X = X[use_cols]\n",
    "        test_X = test_X[use_cols]\n",
    "        \n",
    "    param = {\n",
    "        \"num_leaves\" : 28,\n",
    "        \"learning_rate\" : 0.01,\n",
    "        #\"learning_rate\" : 0.05,\n",
    "        \"num_iterations\" : 2000,\n",
    "        \"objective\" : \"binary\",\n",
    "        \"metric\" : [\"binary_logloss\"],\n",
    "        \"random_state\" : random.randint(0, 10000),\n",
    "        \"max_depth\" : 100\n",
    "    }\n",
    "\n",
    "    THRESHOLD = 0.50\n",
    "    models = []\n",
    "    cv_scores = []\n",
    "    temp = 0\n",
    "    train_pred = []\n",
    "    train_Xs = []\n",
    "    tgt_encode = False\n",
    "\n",
    "    all_indices = sum(folds, [])\n",
    "    for i in range(K):\n",
    "        print(\"======================== fold {} ========================\".format(i+1))\n",
    "        valid_indices = folds[i]\n",
    "        train_indices = list(set(all_indices) - set(valid_indices))\n",
    "        # print(\"train \", len(train_indices), \" , valid \", len(valid_indices))\n",
    "        train_X = X.iloc[train_indices]\n",
    "        try:\n",
    "            train_y = y.iloc[train_indices]\n",
    "        except:\n",
    "            train_y = y[train_indices]\n",
    "        valid_X = X.iloc[valid_indices]\n",
    "        try:\n",
    "            valid_y = y.iloc[valid_indices]\n",
    "        except:\n",
    "            valid_y = y[valid_indices]\n",
    "\n",
    "\n",
    "        if tgt_encode:\n",
    "            for col in cat_tgtenc_cols:\n",
    "                print(col)\n",
    "                train_X, valid_X = prepro.target_encoding(train_X, valid_X, train_y, col, \"y\")\n",
    "\n",
    "\n",
    "        train_data = lgb.Dataset(train_X, label=train_y)\n",
    "        valid_data = lgb.Dataset(valid_X, label=valid_y)\n",
    "\n",
    "        model = lgb.train(\n",
    "            param, \n",
    "            train_data, \n",
    "            valid_sets=valid_data, \n",
    "            #categorical_feature=categorical_feature,\n",
    "            early_stopping_rounds=40, \n",
    "            verbose_eval=1000,\n",
    "\n",
    "        )\n",
    "        pred = model.predict(valid_X)\n",
    "        train_pred.append(pred)\n",
    "        pred = np.where(pred < THRESHOLD, 0, 1)\n",
    "        temp += np.sum(pred)\n",
    "\n",
    "        score = accuracy_score(pred, valid_y)\n",
    "\n",
    "        models.append(model)\n",
    "        cv_scores.append(score)\n",
    "\n",
    "\n",
    "    print(\"cv score : \", np.mean(cv_scores))    \n",
    "    print(\"cv ratio : \", temp / SIZE)\n",
    "    cvs.append(np.mean(cv_scores))\n",
    "    \n",
    "    \n",
    "    preds = []\n",
    "    if tgt_encode:\n",
    "        for col in cat_tgtenc_cols:\n",
    "            print(col)\n",
    "            X, test_X = prepro.target_encoding(X, test_X, y, col, \"y\")\n",
    "\n",
    "    for i in range(K):\n",
    "        model = models[i]\n",
    "        pred = model.predict(test_X)\n",
    "        preds.append(pred)\n",
    "        print(np.sum(pred) / pred.shape[0])\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    preds = np.mean(preds, axis=0)\n",
    "    test_pred_features.append(preds) #\n",
    "    \n",
    "\n",
    "\n",
    "    train_df[\"pred\"] = 0\n",
    "    train_df[\"y\"] = y\n",
    "    for i in range(K):\n",
    "        train_df[\"pred\"].iloc[folds[i]] = train_pred[i]\n",
    "    \n",
    "    train_pred_features.append(train_df[\"pred\"].values) #\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    index = np.argsort(cvs)[::-1][:i]\n",
    "    print(index)\n",
    "    train_pred_f = np.array(train_pred_features)[index]\n",
    "    test_pred_f = np.array(test_pred_features)[index]\n",
    "    train_pred_f = np.mean(train_pred_f, axis=0)\n",
    "    print(train_pred_f.shape)\n",
    "    train_pred_f = np.where(train_pred_f < THRESHOLD, 0, 1)\n",
    "    acc = accuracy_score(train_pred_f, y)\n",
    "    print(\"{} preds : cv is {}\".format(i, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.where(np.mean(np.array(train_pred_features)[[9, 7, 4, 0, 3]], axis=0) < THRESHOLD, 0, 1)\n",
    "accuracy_score(p, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame({'y': p})\n",
    "submit_df.index.name = 'id'\n",
    "submit_df.to_csv('../Submissions/ensemble.csv'.format(K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
