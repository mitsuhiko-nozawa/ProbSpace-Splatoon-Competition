{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Model\n",
    "#### cv score :  0.5432514177693761 (5 folds, model3)\n",
    "#### cv score :  ?? (10 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from Functions import prepro, NNModel\n",
    "import warnings\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132250, 944)\n",
      "(28340, 943)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../../data/Processed/train3.csv.gz\")\n",
    "test_df = pd.read_csv(\"../../data/Processed/test3.csv.gz\")\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[\"y\"]\n",
    "train_df = train_df.drop(\"y\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "scale\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "# make input\n",
    "\n",
    "\n",
    "drop_cols = [\"id\", \"lobby\", \"lobby-mode\",  \"period\", \"game-ver\", \"A1-weapon\", \"A2-weapon\", \"A3-weapon\", \"A4-weapon\", \\\n",
    "              \"B1-weapon\", \"B2-weapon\", \"B3-weapon\", \"B4-weapon\"]\n",
    "\n",
    "categorical_feature = [col for col in train_df.dtypes[train_df.dtypes == \"object\"].index.to_list() if col not in drop_cols]\n",
    "\n",
    "X, test_X = prepro.make_input(train_df, test_df, drop_cols, categorical_encode=True, scaler=True, verbose=False)\n",
    "\n",
    "#X[categorical_feature] = X[categorical_feature].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "fold  1  size is  26450\n",
      "fold  2  size is  26450\n",
      "fold  3  size is  26450\n",
      "fold  4  size is  26450\n",
      "fold  5  size is  26450\n",
      "successfully split\n"
     ]
    }
   ],
   "source": [
    "# 全データを5つに分割\n",
    "random.seed(random.randint(0, 10000))\n",
    "SIZE = X.shape[0]\n",
    "K = 5\n",
    "cat_tgtenc_cols = [\"mode\", \"stage\", \"team-category1-A\", \"team-category1-B\"]\n",
    "#cat_tgtenc_cols = [\"mode\", \"stage\"]\n",
    "\n",
    "folds = prepro.make_stratified_kfolds(X, y, K, shuffle=True)\n",
    "print(len(folds))\n",
    "for i, fold in enumerate(folds):\n",
    "    print(\"fold \", i+1, \" size is \", len(fold))\n",
    "    \n",
    "    \n",
    "if SIZE != len(set(sum(folds, []))):\n",
    "    print(\"error is occuring in spliting\")\n",
    "else :\n",
    "    print(\"successfully split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== fold 1 ========================\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 105800 samples, validate on 26450 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "105800/105800 [==============================] - 144s 1ms/sample - loss: 0.6996 - val_loss: 0.6906\n",
      "Epoch 2/10\n",
      "105800/105800 [==============================] - 115s 1ms/sample - loss: 0.6901 - val_loss: 0.6876\n",
      "Epoch 3/10\n",
      "105800/105800 [==============================] - 102s 960us/sample - loss: 0.6879 - val_loss: 0.6860\n",
      "Epoch 4/10\n",
      "105800/105800 [==============================] - 111s 1ms/sample - loss: 0.6861 - val_loss: 0.6853\n",
      "Epoch 5/10\n",
      "105800/105800 [==============================] - 115s 1ms/sample - loss: 0.6846 - val_loss: 0.6844\n",
      "Epoch 6/10\n",
      "105800/105800 [==============================] - 119s 1ms/sample - loss: 0.6804 - val_loss: 0.6846\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.50\n",
    "models = []\n",
    "cv_scores = []\n",
    "temp = 0\n",
    "train_pred = []\n",
    "\n",
    "all_indices = sum(folds, [])\n",
    "for i in range(K):\n",
    "    print(\"======================== fold {} ========================\".format(i+1))\n",
    "    valid_indices = folds[i]\n",
    "    train_indices = list(set(all_indices) - set(valid_indices))\n",
    "    # print(\"train \", len(train_indices), \" , valid \", len(valid_indices))\n",
    "    train_X = X.iloc[train_indices]\n",
    "    train_y = y.iloc[train_indices]\n",
    "    valid_X = X.iloc[valid_indices]\n",
    "    valid_y = y.iloc[valid_indices]\n",
    "    \n",
    "    \n",
    "    model = NNModel.make_model2(X, test_X, categorical_feature)\n",
    "    #model = NNModel.make_model(X, test_X, categorical_feature)\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_X = NNModel.prepro_nn(train_X, categorical_feature)\n",
    "    train_y = train_y.values.reshape(-1, 1)\n",
    "    valid_X = NNModel.prepro_nn(valid_X, categorical_feature)\n",
    "    valid_y = valid_y.values.reshape(-1, 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    cb = EarlyStopping(monitor='val_loss', patience=1)\n",
    "\n",
    "    model.fit(\n",
    "        train_X, \n",
    "        train_y,\n",
    "        batch_size=256,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        callbacks=[cb],\n",
    "        validation_data=(valid_X, valid_y),\n",
    "    )\n",
    "    \n",
    "    pred = model.predict(valid_X)\n",
    "    pred = np.where(pred < THRESHOLD, 0, 1)\n",
    "    train_pred.append(pred)\n",
    "    temp += np.sum(pred)\n",
    "    \n",
    "    score = accuracy_score(pred, valid_y)\n",
    "    \n",
    "    models.append(model)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    \n",
    "print(\"cv score : \", np.mean(cv_scores))    \n",
    "print(\"cv ratio : \", temp / SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "test_X = NNModel.prepro_nn(test_X, categorical_feature)\n",
    "\n",
    "for i in range(K):\n",
    "    model = models[i]\n",
    "    pred = model.predict(test_X, batch_size=128).reshape(-1, )\n",
    "    preds.append(pred)\n",
    "    print(np.sum(pred) / pred.shape[0])\n",
    "    \n",
    "preds = np.array(preds)\n",
    "preds = np.mean(preds, axis=0)\n",
    "print(np.sum(preds) / preds.shape[0])\n",
    "\n",
    "\n",
    "temp = pd.DataFrame({\"pred\":preds})\n",
    "temp.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.where(preds < THRESHOLD, 0, 1)\n",
    "print(np.sum(preds) / preds.shape[0])\n",
    "\n",
    "submit_df = pd.DataFrame({'y': preds})\n",
    "submit_df.index.name = 'id'\n",
    "submit_df.to_csv('../Submissions/submission_NN_3_{}.csv'.format(K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル解釈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(models[1].feature_importance(), index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "display(importance[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance[\"importance\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"pred\"] = 0\n",
    "train_df[\"y\"] = y.values\n",
    "for i in range(K):\n",
    "    train_df[\"pred\"].iloc[folds[i]] = train_pred[i].reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_df[train_df[\"y\"] != train_df[\"pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df[result_df[\"mode\"] == \"nawabari\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"hoko\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"asari\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"area\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"yagura\"].shape[0]/result_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import category_encoders.target_encoder as te\n",
    "\n",
    "import random\n",
    "\n",
    "def make_input(df1, df2, drop_col, categorical_encode, scaler, verbose):\n",
    "\n",
    "    all_df = pd.concat([df1, df2])\n",
    "    df1 = df1.drop(columns=drop_col, axis=1)\n",
    "    df2 = df2.drop(columns=drop_col, axis=1)\n",
    "    cols = df1.columns\n",
    "    for col in cols:\n",
    "        if verbose:\n",
    "            print(col)\n",
    "\n",
    "\n",
    "        elif df2[col].dtype in [int, float]:\n",
    "            if scaler and \"onehot\" not in col:\n",
    "                df1[col] = df1[col].apply(np.log1p)\n",
    "                df2[col] = df2[col].apply(np.log1p)\n",
    "                scaler = StandardScaler()\n",
    "                print(\"scale\")\n",
    "                scaler.fit(all_df[col].values.reshape(-1, 1))\n",
    "                df1[col] = scaler.transform(df1[col].values.reshape(-1, 1))\n",
    "                df2[col] = scaler.transform(df2[col].values.reshape(-1, 1))\n",
    "            continue\n",
    "        if categorical_encode:\n",
    "            lbl = LabelEncoder()\n",
    "            obj = all_df[col].unique()\n",
    "            lbl.fit(obj)\n",
    "            df1[col] = lbl.transform(df1[col])\n",
    "            df2[col] = lbl.transform(df2[col])\n",
    "    print(\"complete\")\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
