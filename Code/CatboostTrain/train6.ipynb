{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Boost\n",
    "#### cv score :  0.5639017013232513 (5 folds, LB 0.5609)\n",
    "#### cv score :  0.5639017013232513 (5 folds, find rare, LB 0.5575)\n",
    "#### cv score :  0.571281663516068 ... (LB 0.555) onehotなし、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from Functions import prepro\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "from catboost import Pool, CatBoostClassifier, CatBoost\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "FEATURE_SELECTION = False\n",
    "tgt_encode = False\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66125, 304)\n",
      "(28340, 303)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../../data/Processed/train2.csv\")\n",
    "test_df = pd.read_csv(\"../../data/Processed/test2.csv\")\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[\"y\"].values\n",
    "train_df = train_df.drop(\"y\", axis=1)\n",
    "\n",
    "train_df[\"A1-level\"] = train_df[\"A1-level\"].astype(float)\n",
    "test_df[\"A1-level\"] = test_df[\"A1-level\"].astype(float)\n",
    "train_df[\"B1-level\"] = train_df[\"B1-level\"].astype(float)\n",
    "test_df[\"B1-level\"] = test_df[\"B1-level\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add disconnection info\n",
    "\n",
    "train_df = prepro.add_disconnection(train_df)\n",
    "test_df = prepro.add_disconnection(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add info about numeric column\n",
    "# 武器データの中のnum_colsを持つ特徴について、チーム内の統計量を計算、levelは結構効いてる\n",
    "\n",
    "# num_cols = [\"level\", \"range\", \"rapid\", \"atack\", \"ink-sub\", \"fav-main\", \"good-special\"]\n",
    "\n",
    "num_cols = [\n",
    "    \"level\", \"range-main\", \"range-bullet-main\", \"distant-range_sub\", \n",
    "    \"rapid\", \"atack\", \"ink-sub\", \"fav-main\", \"good-special\", \"DPS\", \"kill_time_ika-main\",\n",
    "    \"front_gap_human-main\", \"rensya_frame-main\", \"saidai_damege-main\", \"damage_min-sub\", \n",
    "    \"damage_max-sub\", \"install_num-sub\", \"good-sub\", \"damage_max-special\", \n",
    "    \"duration-special\", \"good-special\", \"direct_rad-special\", \"distant_rad-special\"\n",
    "]\n",
    "\n",
    "cols = [col for col in train_df.columns if \"A1\" in col or \"A2\" in col or \"A3\" in col or \"A4\" in col or \n",
    "        \"B1\" in col or \"B2\" in col or \"B3\" in col or \"B4\" in col]\n",
    "drop_cols = []\n",
    "for col1 in cols:\n",
    "    f = True\n",
    "    for col2 in num_cols:\n",
    "        if col2 in col1:\n",
    "            f = False\n",
    "    if f and train_df[col1].dtype in [int, float]:\n",
    "        drop_cols.append(col1)\n",
    "        \n",
    "train_df = train_df.drop(columns=drop_cols)\n",
    "test_df = test_df.drop(columns=drop_cols)\n",
    "        \n",
    "    \n",
    "\n",
    "train_df = prepro.add_numeric_info(train_df, num_cols)\n",
    "test_df = prepro.add_numeric_info(test_df, num_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 欠損値埋め先にやろう\n",
    "欠損値がある列\n",
    "\n",
    "rank, weapon, level ⇨　回線切れ or ナワバリ\n",
    "\n",
    "weaponの欠損に並んでそれに関係ある列、A3, A4, B3, B4 ⇨ 回線切れ\n",
    "\n",
    "level, weaponが消えていたら回線切れ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rankの欠損値を埋める\n",
    "train_df, test_df = prepro.fillna_rank(train_df, test_df)\n",
    "\n",
    "#そのほかの欠損値を埋める\n",
    "train_df, test_df = prepro.fillna(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.isnull().sum().sum())\n",
    "print(test_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count reskin, by mode\n",
    "print(\"reskin\")\n",
    "train_df, test_df = prepro.count_reskin(train_df, test_df)\n",
    "train_df, test_df = prepro.count_reskin_by_mode(train_df, test_df)\n",
    "\n",
    "# count mainweapon, by mode\n",
    "print(\"mainweapon\")\n",
    "train_df, test_df = prepro.count_mainweapon(train_df, test_df)\n",
    "train_df, test_df = prepro.count_mainweapon_by_mode(train_df, test_df)\n",
    "\n",
    "# count subweapon, by mode\n",
    "print(\"subweapon\")\n",
    "train_df, test_df = prepro.count_subweapon(train_df, test_df)\n",
    "train_df, test_df = prepro.count_subweapon_by_mode(train_df, test_df)\n",
    "\n",
    "# count special, by mode\n",
    "print(\"special\")\n",
    "train_df, test_df = prepro.count_special(train_df, test_df)\n",
    "train_df, test_df = prepro.count_special_by_mode(train_df, test_df)\n",
    "\n",
    "\n",
    "#identify A1\n",
    "train_df, test_df = prepro.identify_A1(train_df, test_df)\n",
    "\n",
    "\n",
    "# 水増し, A1も統計量に含めた特徴を作る場合は水ましより先にやる\n",
    "print(\"mizumashi\")\n",
    "train_df, y = prepro.mizumashi(train_df, y)\n",
    "\n",
    "# is_nawabari\n",
    "train_df, test_df = prepro.is_nawabari(train_df, test_df)\n",
    "\n",
    "# match rank、単体で意味なし\n",
    "train_df, test_df = prepro.match_rank(train_df, test_df)\n",
    "\n",
    "# rankを二列に分ける\n",
    "train_df, test_df = prepro.ranker(train_df, test_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add team info、メインはなくてもいい\n",
    "\n",
    "train_df,  test_df = prepro.addTeamInfo(train_df, test_df, cols=[\"special\", \"subweapon\", \"category1\", \"category2\", \"mainweapon\"])\n",
    "#train_df,  test_df = prepro.addTeamInfo(train_df, test_df, cols=[\"special\", \"subweapon\", \"category1\", \"category2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize team , 良い, メインはカテゴリ数が多すぎてやめた方がいい\n",
    "\n",
    "categorize_col = [\"category1\", \"category2\", \"subweapon\", \"special\", \"mainweapon\"]\n",
    "#categorize_col = [\"category1\", \"category2\", \"subweapon\", \"special\"]\n",
    "for col in categorize_col:\n",
    "    print(col)\n",
    "    train_df, test_df = prepro.categorize_team(train_df, test_df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レアなカテゴリをまとめる、しない方が上がった…\n",
    "\n",
    "#train_df, test_df = prepro.find_rare(train_df, test_df, \"team-category1\")\n",
    "#train_df, test_df = prepro.find_rare(train_df, test_df, \"team-category2\")\n",
    "#train_df, test_df = prepro.find_rare(train_df, test_df, \"team-subweapon\")\n",
    "#train_df, test_df = prepro.find_rare(train_df, test_df, \"team-special\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product categorical feature\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"stage\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-category1-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-category1-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-category2-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-category2-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-mainweapon-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-mainweapon-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-subweapon-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-subweapon-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-special-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"team-special-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"match_rank\")\n",
    "\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-category1-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-category1-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-category2-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-category2-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-mainweapon-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-mainweapon-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-subweapon-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-subweapon-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-special-A\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"team-special-B\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"stage\", \"match_rank\")\n",
    "\n",
    "\"\"\"\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"reskin-A1\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"reskin-A2\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"reskin-A3\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"reskin-A4\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"reskin-B1\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"reskin-B2\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"reskin-B3\")\n",
    "train_df, test_df = prepro.prod(train_df, test_df, \"mode\", \"reskin-B4\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#one hot 落とす\n",
    "drop_cols = [col for col in train_df.columns if \"onehot\" in col]\n",
    "train_df.drop(columns=drop_cols, inplace=True)\n",
    "test_df.drop(columns=drop_cols, inplace=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make input\n",
    "\n",
    "drop_cols = [\n",
    "    \"id\", \"lobby\", \"lobby-mode\",  \"period\", \"game-ver\", \n",
    "    \"A1-weapon\", \"A2-weapon\", \"A3-weapon\", \"A4-weapon\", \n",
    "    \"B1-weapon\", \"B2-weapon\", \"B3-weapon\", \"B4-weapon\",\n",
    "    \"A1-reskin\", \"A2-reskin\", \"A3-reskin\", \"A4-reskin\", \n",
    "    \"B1-reskin\", \"B2-reskin\", \"B3-reskin\", \"B4-reskin\",\n",
    "    \"category1-A1\", \"category1-A2\", \"category1-A3\", \"category1-A4\", \n",
    "    \"category1-B1\", \"category1-B2\", \"category1-B3\", \"category1-B4\",\n",
    "    \"category2-A1\", \"category2-A2\", \"category2-A3\", \"category2-A4\", \n",
    "    \"category2-B1\", \"category2-B2\", \"category2-B3\", \"category2-B4\",\n",
    "    \"mainweapon-A1\", \"mainweapon-A2\", \"mainweapon-A3\", \"mainweapon-A4\", \n",
    "    \"mainweapon-B1\", \"mainweapon-B2\", \"mainweapon-B3\", \"mainweapon-B4\",\n",
    "    \"subweapon-A1\", \"subweapon-A2\", \"subweapon-A3\", \"subweapon-A4\", \n",
    "    \"subweapon-B1\", \"subweapon-B2\", \"subweapon-B3\", \"subweapon-B4\",\n",
    "    \"special-A1\", \"special-A2\", \"special-A3\", \"special-A4\", \n",
    "    \"special-B1\", \"special-B2\", \"special-B3\", \"special-B4\",\n",
    "]\n",
    "\n",
    "X, test_X = prepro.make_input(train_df, test_df, drop_cols, categorical_encode=False, scaler=False, verbose=False)\n",
    "\n",
    "categorical_features_indices = np.where(X.dtypes == \"object\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全データを5つに分割\n",
    "random.seed(random.randint(0, 10000))\n",
    "SIZE = X.shape[0]\n",
    "K = 5\n",
    "cat_tgtenc_cols = [\n",
    "    \"team-category1-A\", \"team-category1-B\", \"team-category2-A\", \"team-category2-B\",\n",
    "    \"team-subweapon-A\", \"team-subweapon-B\", \"team-special-A\", \"team-special-B\"\n",
    "]\n",
    "cat_tgtenc_cols = []\n",
    "\n",
    "#folds = prepro.make_stratified_kfolds(X, y, K, shuffle=True)\n",
    "folds = prepro.make_stratified_kfolds(X, X[\"mode\"].astype(str) + y.astype(str), K, shuffle=True, random_state=random.randint(0, 10000))\n",
    "\n",
    "\n",
    "print(len(folds))\n",
    "for i, fold in enumerate(folds):\n",
    "    print(\"fold \", i+1, \" size is \", len(fold))\n",
    "    \n",
    "    \n",
    "if SIZE != len(set(sum(folds, []))):\n",
    "    print(\"error is occuring in spliting\")\n",
    "else :\n",
    "    print(\"successfully split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"loss_function\" : \"Logloss\",\n",
    "    \"eval_metric\" : \"Logloss\",\n",
    "    \"iterations\":2000,\n",
    "    \"learning_rate\" : 0.05,\n",
    "    \"use_best_model\": True,\n",
    "    \"random_seed\":random.randint(0, 100000),\n",
    "\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "THRESHOLD = 0.50\n",
    "models = []\n",
    "cv_scores = []\n",
    "temp = 0\n",
    "train_pred = []\n",
    "valid_ys = []\n",
    "\n",
    "all_indices = sum(folds, [])\n",
    "for i in range(K):\n",
    "    print(\"======================== fold {} ========================\".format(i+1))\n",
    "    valid_indices = folds[i]\n",
    "    train_indices = list(set(all_indices) - set(valid_indices))\n",
    "    # print(\"train \", len(train_indices), \" , valid \", len(valid_indices))\n",
    "    \n",
    "\n",
    "    train_X = X.iloc[train_indices]\n",
    "    try:\n",
    "        train_y = y.iloc[train_indices]\n",
    "    except:\n",
    "        train_y = y[train_indices]\n",
    "    valid_X = X.iloc[valid_indices]\n",
    "    try:\n",
    "        valid_y = y.iloc[valid_indices]\n",
    "    except:\n",
    "        valid_y = y[valid_indices]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    train_data = Pool(train_X, train_y, cat_features=categorical_features_indices)\n",
    "    valid_data = Pool(valid_X, valid_y, cat_features=categorical_features_indices)\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    \n",
    "    model.fit(\n",
    "        train_data,\n",
    "        eval_set=valid_data,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=100,\n",
    "        use_best_model=True,\n",
    "    )\n",
    "    \n",
    "    pred = model.predict(valid_X, prediction_type='Probability')[:,1]\n",
    "    train_pred.append(pred)\n",
    "    pred = np.where(pred < THRESHOLD, 0, 1)\n",
    "\n",
    "    temp += np.sum(pred) \n",
    "    \n",
    "    score = accuracy_score(pred, valid_y)\n",
    "    \n",
    "    models.append(model)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    \n",
    "print(\"cv score : \", np.mean(cv_scores))    \n",
    "print(\"cv ratio : \", temp / SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(K):\n",
    "    model = models[i]\n",
    "    pred = model.predict(test_X, prediction_type='Probability')[:,1]\n",
    "    preds.append(pred)\n",
    "    print(np.sum(pred) / pred.shape[0])\n",
    "    \n",
    "preds = np.array(preds)\n",
    "preds = np.mean(preds, axis=0)\n",
    "print(np.sum(preds) / preds.shape[0])\n",
    "\n",
    "\n",
    "temp = pd.DataFrame({\"pred\":pred})\n",
    "temp.hist(bins=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.where(preds < THRESHOLD, 0, 1)\n",
    "print(np.sum(preds) / preds.shape[0])\n",
    "\n",
    "submit_df = pd.DataFrame({'y': preds})\n",
    "submit_df.index.name = 'id'\n",
    "submit_df.to_csv('../Submissions/submission_cat_6_{}.csv'.format(K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル解釈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(\n",
    "    (models[0].get_feature_importance() + \n",
    "    models[1].get_feature_importance() + \n",
    "    models[2].get_feature_importance() + \n",
    "    models[3].get_feature_importance() + \n",
    "    models[4].get_feature_importance())/5\n",
    "    , index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "display(importance[:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [index for index in importance.index if \"team\" in index]\n",
    "importance.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"disconnection-A\"] != 0][[\"disconnection-A\", \"disconnection-B\", \"y\", \"pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"pred\"] = 0\n",
    "train_df[\"y\"] = y\n",
    "for i in range(K):\n",
    "    train_df[\"pred\"].iloc[folds[i]] = np.where(train_pred[i] < THRESHOLD, 0, 1)\n",
    "    #train_df[\"pred\"].iloc[folds[i]] = train_pred[i]\n",
    "for mode in train_df[\"mode\"].unique():\n",
    "    rate = train_df[train_df[\"mode\"] == mode][train_df[\"pred\"] == train_df[\"y\"]].shape[0] / train_df[train_df[\"mode\"] == mode].shape[0]\n",
    "    print(\"{} : {}\".format(mode, rate))\n",
    "print(train_df[train_df[\"pred\"] == train_df[\"y\"]].shape[0] / train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_df[train_df[\"y\"] != train_df[\"pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df[result_df[\"mode\"] == \"nawabari\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"hoko\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"asari\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"area\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"yagura\"].shape[0]/result_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df[\"mode\"] == \"nawabari\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type, MAXSIZE=120):\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)[:MAXSIZE]\n",
    "    feature_names = np.array(names)[:MAXSIZE]\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(20,16))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(importance.values.reshape(-1,), importance.index, \"Cat Boost \", MAXSIZE=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = train_df[\"team-subweapon-A\"].value_counts().add(\n",
    "    train_df[\"team-subweapon-B\"].value_counts().add(\n",
    "        test_df[\"team-subweapon-A\"].value_counts().add(\n",
    "            test_df[\"team-subweapon-A\"].value_counts(), fill_value=0\n",
    "        ), fill_value=0\n",
    "    ), fill_value=0\n",
    ").sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(v))\n",
    "plt.bar(x, v)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rare(df1, df2, col, threshold=4):\n",
    "    v_tra = df1[col + \"-A\"].value_counts()\n",
    "    v_trb = df1[col + \"-B\"].value_counts()\n",
    "    v_tea = df2[col + \"-A\"].value_counts()\n",
    "    v_teb = df2[col + \"-B\"].value_counts()\n",
    "    \n",
    "    v_counts = v_tra.add(v_trb, fill_value=0)\n",
    "    v_counts = v_counts.add(v_tea, fill_value=0)\n",
    "    v_counts = v_counts.add(v_teb, fill_value=0)\n",
    "    \n",
    "    #threshold = v_counts.iloc[int(v_counts.shape[0]*0.8)]\n",
    "\n",
    "    tra = df1[col + \"-A\"].unique()\n",
    "    trb = df1[col + \"-B\"].unique()\n",
    "    tea = df2[col + \"-A\"].unique()\n",
    "    teb = df2[col + \"-B\"].unique()\n",
    "\n",
    "    not_appeared = []\n",
    "    print(\"fin count\")\n",
    "    for item in v_counts.index:\n",
    "        if item not in tra or item not in trb or item not in tea or item not in teb or v_tra.loc[item] < 5 or v_trb.loc[item] < 5:\n",
    "            not_appeared.append(item)\n",
    "\n",
    "    print(\"fin find rare\", len(not_appeared))\n",
    "    df1[col + \"-A\"] = df1[col + \"-A\"].map(lambda x: \"rare\" if x in not_appeared else x)\n",
    "    df1[col + \"-B\"] = df1[col + \"-B\"].map(lambda x: \"rare\" if x in not_appeared else x)\n",
    "    df2[col + \"-A\"] = df2[col + \"-A\"].map(lambda x: \"rare\" if x in not_appeared else x)\n",
    "    df2[col + \"-B\"] = df2[col + \"-B\"].map(lambda x: \"rare\" if x in not_appeared else x)\n",
    "\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = find_rare(train_df, test_df, \"team-special\") #473 sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"team-special-A\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
