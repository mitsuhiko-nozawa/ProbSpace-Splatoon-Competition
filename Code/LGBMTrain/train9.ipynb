{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回線切れの数\n",
    "# 武器の詳細追加\n",
    "#### cv score :  0.5490586011342156 (5 folds)\n",
    "#### cv score :  0.551296786389414 (10 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spla/lib/python3.6/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from Functions import prepro\n",
    "import warnings\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132250, 193)\n",
      "(28340, 192)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../../data/Processed/train2.csv\")\n",
    "test_df = pd.read_csv(\"../../data/Processed/test2.csv\")\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 武器の情報を個人ごとからチームごとに変える\n",
    "category1, 2を落とす、\n",
    "\n",
    "他のカテゴリをチームごとにする\n",
    "\n",
    "reskinそのまま"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'suffixes = [\"-A1\", \"-A2\", \"-A3\", \"-A4\", \"-B1\", \"-B2\", \"-B3\", \"-B4\"]\\ndrop_cols = [\"category1\", \"category2\"]\\n\\nfor c in drop_cols:\\n    for s in suffixes:\\n        col = c+s\\n        train_df.drop(col, axis=1, inplace=True)\\n        test_df.drop(col, axis=1, inplace=True)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 落とさないほうが精度上がってしまった。。。\n",
    "\n",
    "\"\"\"suffixes = [\"-A1\", \"-A2\", \"-A3\", \"-A4\", \"-B1\", \"-B2\", \"-B3\", \"-B4\"]\n",
    "drop_cols = [\"category1\", \"category2\"]\n",
    "\n",
    "for c in drop_cols:\n",
    "    for s in suffixes:\n",
    "        col = c+s\n",
    "        train_df.drop(col, axis=1, inplace=True)\n",
    "        test_df.drop(col, axis=1, inplace=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[\"y\"]\n",
    "train_df = train_df.drop(\"y\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add info about numeric column\n",
    "\n",
    "num_cols = [\"level\", \"range\", \"rapid-\", \"atack\"]\n",
    "\n",
    "#train_df = prepro.flat(train_df, num_cols)\n",
    "#test_df = prepro.flat(test_df, num_cols)\n",
    "\n",
    "train_df = prepro.add_numeric_info(train_df, num_cols)\n",
    "test_df = prepro.add_numeric_info(test_df, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160590, 240)\n",
      "special-A\n",
      "special-B\n",
      "subweapon-A\n",
      "subweapon-B\n",
      "category1-A\n",
      "category1-B\n",
      "category2-A\n",
      "category2-B\n",
      "mainweapon-A\n",
      "mainweapon-B\n",
      "(160590, 424)\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "# add team info\n",
    "\n",
    "train_df,  test_df = prepro.addTeamInfo(train_df, test_df, cols=[\"special\", \"subweapon\", \"category1\", \"category2\", \"mainweapon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add disconnection info\n",
    "\n",
    "train_df = prepro.add_disconnection(train_df)\n",
    "test_df = prepro.add_disconnection(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category1\n",
      "category2\n",
      "subweapon\n",
      "special\n",
      "mainweapon\n"
     ]
    }
   ],
   "source": [
    "# categorize team\n",
    "\n",
    "categorize_col = [\"category1\", \"category2\", \"subweapon\", \"special\", \"mainweapon\"]\n",
    "for col in categorize_col:\n",
    "    print(col)\n",
    "    train_df_, test_df_ = prepro.categorize_team(train_df, test_df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode\n",
      "1         nawabari\n",
      "2         nawabari\n",
      "3         nawabari\n",
      "4         nawabari\n",
      "5             hoko\n",
      "            ...   \n",
      "132246        hoko\n",
      "132247        area\n",
      "132248        area\n",
      "132249       asari\n",
      "132250       asari\n",
      "Name: mode, Length: 132250, dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['y'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1cce1b0a105f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_tgtenc_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/prob_space/spla_prob/Nozawa/Functions/prepro.py\u001b[0m in \u001b[0;36mtarget_encoding\u001b[0;34m(df1, df2, y_, col, y_col, nfolds)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mdf1_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/spla/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/spla/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/spla/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['y'] not in index\""
     ]
    }
   ],
   "source": [
    "#target encoding\n",
    "\n",
    "#cat_tgtenc_cols = [\"mode\", \"stage\", \"team-category1-A\", \"team-category1-B\", \n",
    "#                  \"team-category2-A\", \"team-category2-B\", \"team-subweapon-A\", \"team-subweapon-B\", \"team-special-A\", \"team-special-B\"]\n",
    "\n",
    "cat_tgtenc_cols = [\"mode\", \"stage\", \"team-category1-A\", \"team-category1-B\"]\n",
    "for col in cat_tgtenc_cols:\n",
    "    print(col)\n",
    "    train_df, test_df = prepro.target_encoding(train_df, test_df, y, col, \"y\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make input\n",
    "\n",
    "# categorical_feature = train_df.dtypes[train_df.dtypes == \"object\"].index.to_list()\n",
    "\n",
    "drop_cols = [\"id\", \"lobby\", \"lobby-mode\",  \"period\", \"game-ver\", \"A1-weapon\", \"A2-weapon\", \"A3-weapon\", \"A4-weapon\", \\\n",
    "              \"B1-weapon\", \"B2-weapon\", \"B3-weapon\", \"B4-weapon\"]\n",
    "\n",
    "categorical_feature = [col for col in train_df.dtypes[train_df.dtypes == \"object\"].index.to_list() if col not in drop_cols]\n",
    "X, test_X = prepro.make_input(train_df, test_df, drop_cols, categorical_encode=True, verbose=False)\n",
    "\n",
    "X[categorical_feature] = X[categorical_feature].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全データを5つに分割\n",
    "SIZE = X.shape[0]\n",
    "K = 5\n",
    "\n",
    "folds = prepro.make_kfolds(SIZE, K)\n",
    "print(len(folds))\n",
    "for i, fold in enumerate(folds):\n",
    "    print(\"fold \", i+1, \" size is \", len(fold))\n",
    "    \n",
    "\n",
    "    \n",
    "if SIZE != len(set(sum(folds, []))):\n",
    "    print(\"error is occuring in spliting\")\n",
    "else :\n",
    "    print(\"successfully split\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"num_leaves\" : 20,\n",
    "    \"n_estimators\" : 100,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"num_iterations\" : 1000,\n",
    "    \"objective\" : \"binary\",\n",
    "    \"metric\" : [\"binary_logloss\"],\n",
    "    \"random_state\" : 1234,\n",
    "}\n",
    "\n",
    "THRESHOLD = 0.50\n",
    "models = []\n",
    "cv_scores = []\n",
    "temp = 0\n",
    "train_pred = []\n",
    "\n",
    "all_indices = sum(folds, [])\n",
    "for i in range(K):\n",
    "    print(\"======================== fold {} ========================\".format(i))\n",
    "    valid_indices = folds[i]\n",
    "    train_indices = list(set(all_indices) - set(valid_indices))\n",
    "    # print(\"train \", len(train_indices), \" , valid \", len(valid_indices))\n",
    "    train_X = X.iloc[train_indices].values\n",
    "    train_y = y.iloc[train_indices].values\n",
    "    valid_X = X.iloc[valid_indices].values\n",
    "    valid_y = y.iloc[valid_indices].values\n",
    "    \n",
    "    train_data = lgb.Dataset(train_X, label=train_y)\n",
    "    valid_data = lgb.Dataset(valid_X, label=valid_y)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        param, \n",
    "        train_data, \n",
    "        valid_sets=valid_data, \n",
    "        #categorical_feature=categorical_feature,\n",
    "        early_stopping_rounds=10, \n",
    "        verbose_eval=20,\n",
    "        \n",
    "    )\n",
    "    pred = model.predict(valid_X)\n",
    "    pred = np.where(pred < THRESHOLD, 0, 1)\n",
    "    train_pred.append(pred)\n",
    "    temp += np.sum(pred)\n",
    "    \n",
    "    score = accuracy_score(pred, valid_y)\n",
    "    \n",
    "    models.append(model)\n",
    "    cv_scores.append(score)\n",
    "    \n",
    "    \n",
    "print(\"cv score : \", np.mean(cv_scores))    \n",
    "print(\"cv ratio : \", temp / SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(K):\n",
    "    model = models[i]\n",
    "    pred = model.predict(test_X)\n",
    "    preds.append(pred)\n",
    "    print(np.sum(pred) / pred.shape[0])\n",
    "    \n",
    "preds = np.array(preds)\n",
    "preds = np.mean(preds, axis=0)\n",
    "print(np.sum(preds) / preds.shape[0])\n",
    "\n",
    "\n",
    "temp = pd.DataFrame({\"pred\":pred})\n",
    "temp.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.where(preds < THRESHOLD, 0, 1)\n",
    "print(np.sum(preds) / preds.shape[0])\n",
    "\n",
    "submit_df = pd.DataFrame({'y': preds})\n",
    "submit_df.index.name = 'id'\n",
    "submit_df.to_csv('../Submissions/submission9_{}.csv'.format(K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル解釈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(models[1].feature_importance(), index=X.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "display(importance[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance[\"importance\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"pred\"] = 0\n",
    "train_df[\"y\"] = y.values\n",
    "for i in range(K):\n",
    "    train_df[\"pred\"].iloc[folds[i]] = train_pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_df[train_df[\"y\"] != train_df[\"pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df[result_df[\"mode\"] == \"nawabari\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"hoko\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"asari\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"area\"].shape[0]/result_df.shape[0])\n",
    "print(result_df[result_df[\"mode\"] == \"yagura\"].shape[0]/result_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
